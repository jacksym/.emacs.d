import numpy as np
import matplotlib.pyplot as plt
from scipy import optimize, integrate

def formula(t, nu, mu):
    def beta(x, y):
        integrand = lambda t: t**(x-1) * (1-t)**(y-1)
        x = np.linspace(0, 1, 20)
        integral = np.trapz(integrand(x), x=x)
        print(integral)
        return integral
    pdf = lambda u: (1/(np.sqrt(nu)*beta(0.5, (nu/2)))) * (1+((u-mu)**2)/nu) ** (-(nu+1)/2)
    cdf = np.array([])
    for i in t:
        integral, err = integrate.quad(pdf, np.min(t), i, limit=20)
        cdf = np.append(cdf, integral)
    return cdf


meas = np.linspace(-6, 6, 100)

params = [3, 0]

cdf = formula(meas, *params)

